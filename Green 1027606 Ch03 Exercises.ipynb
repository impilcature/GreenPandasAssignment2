{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787bcf8b",
   "metadata": {},
   "source": [
    "# Daniel Green\n",
    "## 1027606\n",
    "### Chapter 03 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c021a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a4f7f",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "We want to look at data for the FAANG stocks (Facebook, Apple, Amazon, Netflix, and Google), but we were given each as a separate CSV file. Make them into a single file and store the dataframe of the FAANG data as `faang`:\n",
    "1. Read each file in.\n",
    "2. Add a column to each dataframe indicating the ticker it is for.  This is how you look up a stock.  In this case, the filename happens to be the ticker symbol\n",
    "3. Append them together into a single dataframe.\n",
    "4. Save the result to a faang.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d9d2cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of     ticker        date         high          low         open        close  \\\n",
      "0       FB  2018-01-02   181.580002   177.550003   177.679993   181.419998   \n",
      "1       FB  2018-01-03   184.779999   181.330002   181.880005   184.669998   \n",
      "2       FB  2018-01-04   186.210007   184.100006   184.899994   184.330002   \n",
      "3       FB  2018-01-05   186.899994   184.929993   185.589996   186.850006   \n",
      "4       FB  2018-01-08   188.899994   186.330002   187.199997   188.279999   \n",
      "..     ...         ...          ...          ...          ...          ...   \n",
      "246   GOOG  2018-12-24  1003.539978   970.109985   973.900024   976.219971   \n",
      "247   GOOG  2018-12-26  1040.000000   983.000000   989.010010  1039.459961   \n",
      "248   GOOG  2018-12-27  1043.890015   997.000000  1017.150024  1043.880005   \n",
      "249   GOOG  2018-12-28  1055.560059  1033.099976  1049.619995  1037.079956   \n",
      "250   GOOG  2018-12-31  1052.699951  1023.590027  1050.959961  1035.609985   \n",
      "\n",
      "         volume  \n",
      "0    18151900.0  \n",
      "1    16886600.0  \n",
      "2    13880900.0  \n",
      "3    13574500.0  \n",
      "4    17994700.0  \n",
      "..          ...  \n",
      "246   1590300.0  \n",
      "247   2373300.0  \n",
      "248   2109800.0  \n",
      "249   1414800.0  \n",
      "250   1493300.0  \n",
      "\n",
      "[1255 rows x 7 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>181.580002</td>\n",
       "      <td>177.550003</td>\n",
       "      <td>177.679993</td>\n",
       "      <td>181.419998</td>\n",
       "      <td>18151900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>184.779999</td>\n",
       "      <td>181.330002</td>\n",
       "      <td>181.880005</td>\n",
       "      <td>184.669998</td>\n",
       "      <td>16886600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>186.210007</td>\n",
       "      <td>184.100006</td>\n",
       "      <td>184.899994</td>\n",
       "      <td>184.330002</td>\n",
       "      <td>13880900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>186.899994</td>\n",
       "      <td>184.929993</td>\n",
       "      <td>185.589996</td>\n",
       "      <td>186.850006</td>\n",
       "      <td>13574500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>188.899994</td>\n",
       "      <td>186.330002</td>\n",
       "      <td>187.199997</td>\n",
       "      <td>188.279999</td>\n",
       "      <td>17994700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date        high         low        open       close  \\\n",
       "0     FB  2018-01-02  181.580002  177.550003  177.679993  181.419998   \n",
       "1     FB  2018-01-03  184.779999  181.330002  181.880005  184.669998   \n",
       "2     FB  2018-01-04  186.210007  184.100006  184.899994  184.330002   \n",
       "3     FB  2018-01-05  186.899994  184.929993  185.589996  186.850006   \n",
       "4     FB  2018-01-08  188.899994  186.330002  187.199997  188.279999   \n",
       "\n",
       "       volume  \n",
       "0  18151900.0  \n",
       "1  16886600.0  \n",
       "2  13880900.0  \n",
       "3  13574500.0  \n",
       "4  17994700.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang = pd.DataFrame()\n",
    "for ticker in ['fb', 'aapl', 'amzn', 'nflx', 'goog']:\n",
    "    df = pd.read_csv(f'./exercises/{ticker}.csv')\n",
    "    df.insert(0, 'ticker', ticker.upper())     # second requirement, add ticker for stock\n",
    "    faang = faang.append(df)\n",
    "\n",
    "faang.to_csv('faang.csv', index=False)\n",
    "print(faang.head) # ugly display but data valid should use df.head()\n",
    "faang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8de975",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "With `faang`, use type conversion to change the `date` column to datetime and the `volume` column to integers. Then, sort by `date` and `ticker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e47ca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>102223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1170.510010</td>\n",
       "      <td>1172.000000</td>\n",
       "      <td>1189.010010</td>\n",
       "      <td>2694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>181.580002</td>\n",
       "      <td>177.550003</td>\n",
       "      <td>177.679993</td>\n",
       "      <td>181.419998</td>\n",
       "      <td>18151900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1066.939941</td>\n",
       "      <td>1045.229980</td>\n",
       "      <td>1048.339966</td>\n",
       "      <td>1065.000000</td>\n",
       "      <td>1237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>201.649994</td>\n",
       "      <td>195.419998</td>\n",
       "      <td>196.100006</td>\n",
       "      <td>201.070007</td>\n",
       "      <td>10966900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date         high          low         open        close  \\\n",
       "0   AAPL 2018-01-02    43.075001    42.314999    42.540001    43.064999   \n",
       "0   AMZN 2018-01-02  1190.000000  1170.510010  1172.000000  1189.010010   \n",
       "0     FB 2018-01-02   181.580002   177.550003   177.679993   181.419998   \n",
       "0   GOOG 2018-01-02  1066.939941  1045.229980  1048.339966  1065.000000   \n",
       "0   NFLX 2018-01-02   201.649994   195.419998   196.100006   201.070007   \n",
       "\n",
       "      volume  \n",
       "0  102223600  \n",
       "0    2694500  \n",
       "0   18151900  \n",
       "0    1237600  \n",
       "0   10966900  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang = faang.assign(\n",
    "    date=lambda x: pd.to_datetime(x.date), #functionname=lambda arguments : expression\n",
    "    volume=lambda x: x.volume.astype(int)\n",
    ").sort_values(\n",
    "    ['date', 'ticker']\n",
    ")\n",
    "\n",
    "faang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbf4fb",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "Find the 7 rows with the lowest value for `volume`, using built in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8842d094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>1135.819946</td>\n",
       "      <td>1100.020020</td>\n",
       "      <td>1135.819946</td>\n",
       "      <td>1102.890015</td>\n",
       "      <td>679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>1037.589966</td>\n",
       "      <td>1022.398987</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1023.880005</td>\n",
       "      <td>691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>1080.469971</td>\n",
       "      <td>1066.150024</td>\n",
       "      <td>1079.000000</td>\n",
       "      <td>1079.239990</td>\n",
       "      <td>766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>1159.589966</td>\n",
       "      <td>1149.589966</td>\n",
       "      <td>1156.979980</td>\n",
       "      <td>1152.839966</td>\n",
       "      <td>798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>1255.541992</td>\n",
       "      <td>1246.010010</td>\n",
       "      <td>1249.900024</td>\n",
       "      <td>1249.099976</td>\n",
       "      <td>848600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1194.625977</td>\n",
       "      <td>1205.020020</td>\n",
       "      <td>1207.770020</td>\n",
       "      <td>870800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>1211.839966</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1207.329956</td>\n",
       "      <td>887400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker       date         high          low         open        close  \\\n",
       "126   GOOG 2018-07-03  1135.819946  1100.020020  1135.819946  1102.890015   \n",
       "226   GOOG 2018-11-23  1037.589966  1022.398987  1030.000000  1023.880005   \n",
       "99    GOOG 2018-05-24  1080.469971  1066.150024  1079.000000  1079.239990   \n",
       "130   GOOG 2018-07-10  1159.589966  1149.589966  1156.979980  1152.839966   \n",
       "152   GOOG 2018-08-09  1255.541992  1246.010010  1249.900024  1249.099976   \n",
       "159   GOOG 2018-08-20  1211.000000  1194.625977  1205.020020  1207.770020   \n",
       "161   GOOG 2018-08-22  1211.839966  1199.000000  1200.000000  1207.329956   \n",
       "\n",
       "     volume  \n",
       "126  679000  \n",
       "226  691500  \n",
       "99   766800  \n",
       "130  798400  \n",
       "152  848600  \n",
       "159  870800  \n",
       "161  887400  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang.nsmallest(7, 'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eaa308",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "Right now, the data is somewhere between long and wide format. Use `melt()` to make it completely long format.\n",
    "HINT: date and ticker are our ID variables (they uniquely identify each row).  We need to melt the rest so that we don't have separate columns for open, high, low, close, volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "296f2c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>42.540001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>1172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FB</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>177.679993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>1048.339966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>open</td>\n",
       "      <td>196.100006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date variable        value\n",
       "0   AAPL 2018-01-02     open    42.540001\n",
       "1   AMZN 2018-01-02     open  1172.000000\n",
       "2     FB 2018-01-02     open   177.679993\n",
       "3   GOOG 2018-01-02     open  1048.339966\n",
       "4   NFLX 2018-01-02     open   196.100006"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_faang = faang.melt(\n",
    "    id_vars=['ticker', 'date'], \n",
    "    value_vars=['open', 'high', 'low', 'close', 'volume']\n",
    ")\n",
    "melted_faang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c5119",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Suppose we found out there was a glitch in how the data was recorded on July 26, 2018. How should we handle this?\n",
    "__________________________________________________\n",
    "A glitch in the data could happen by either analysis inconsistencies or misunderstanding the data.  With such a narrow scope with which to start it would be helpful to take a sample before and after that date/time stamp and see what happened during that time.  If the original data import confirms the data is accurate as imported from the source the next step is to look at outside influences to make sure the data was valid for that time period.  If the data is not valid then a data correction would be warranted with heavy documentation on both what was found and how it was corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcddbd3c",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "The European Centre for Disease Prevention and Control (ECDC) provides an open dataset on COVID-19 cases called, [*daily number of new reported cases of COVID-19 by country worldwide*](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide). This dataset is updated daily, but we will use a snapshot that contains data from January 1, 2020 through September 18, 2020. Clean and pivot the data so that it is in wide format:\n",
    "\n",
    "1. Read in the `covid19_cases.csv` file.\n",
    "2. Create a `date` column using the data in the `dateRep` column and the `pd.to_datetime()` function.\n",
    "3. Set the `date` column as the index and sort the index.\n",
    "4. Replace occurrences of `United_States_of_America` and `United_Kingdom` with `USA` and `UK`, respectively.\n",
    "5. Using the `countriesAndTerritories` column, filter the data down to Argentina, Brazil, China, Colombia, India, Italy, Mexico, Peru, Russia, Spain, Turkey, the UK, and the USA.\n",
    "6. Pivot the data so that the index contains the dates, the columns contain the country names, and the values are the case counts in the `cases` column. Be sure to fill in `NaN` values with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ee17c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>China</th>\n",
       "      <th>Colombia</th>\n",
       "      <th>India</th>\n",
       "      <th>Italy</th>\n",
       "      <th>Mexico</th>\n",
       "      <th>Peru</th>\n",
       "      <th>Russia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Turkey</th>\n",
       "      <th>UK</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-14</th>\n",
       "      <td>10778.0</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7355.0</td>\n",
       "      <td>92071.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>4408.0</td>\n",
       "      <td>6787.0</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>27404.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>33871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-15</th>\n",
       "      <td>9056.0</td>\n",
       "      <td>15155.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5573.0</td>\n",
       "      <td>83809.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>3335.0</td>\n",
       "      <td>4241.0</td>\n",
       "      <td>5509.0</td>\n",
       "      <td>9437.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>34841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>9908.0</td>\n",
       "      <td>36653.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6698.0</td>\n",
       "      <td>90123.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>4160.0</td>\n",
       "      <td>5529.0</td>\n",
       "      <td>11193.0</td>\n",
       "      <td>1742.0</td>\n",
       "      <td>3103.0</td>\n",
       "      <td>51473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-17</th>\n",
       "      <td>11893.0</td>\n",
       "      <td>36820.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7787.0</td>\n",
       "      <td>97894.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>11291.0</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>3991.0</td>\n",
       "      <td>24598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-18</th>\n",
       "      <td>11674.0</td>\n",
       "      <td>36303.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7568.0</td>\n",
       "      <td>96424.0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>5698.0</td>\n",
       "      <td>5762.0</td>\n",
       "      <td>14389.0</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>3395.0</td>\n",
       "      <td>43567.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "countriesAndTerritories  Argentina   Brazil  China  Colombia    India   Italy  \\\n",
       "date                                                                            \n",
       "2020-01-01                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
       "2020-01-02                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
       "2020-01-03                     0.0      0.0   17.0       0.0      0.0     0.0   \n",
       "2020-01-04                     0.0      0.0    0.0       0.0      0.0     0.0   \n",
       "2020-01-05                     0.0      0.0   15.0       0.0      0.0     0.0   \n",
       "...                            ...      ...    ...       ...      ...     ...   \n",
       "2020-09-14                 10778.0  14768.0   29.0    7355.0  92071.0  1456.0   \n",
       "2020-09-15                  9056.0  15155.0   22.0    5573.0  83809.0  1008.0   \n",
       "2020-09-16                  9908.0  36653.0   24.0    6698.0  90123.0  1229.0   \n",
       "2020-09-17                 11893.0  36820.0    7.0    7787.0  97894.0  1452.0   \n",
       "2020-09-18                 11674.0  36303.0   44.0    7568.0  96424.0  1583.0   \n",
       "\n",
       "countriesAndTerritories  Mexico    Peru  Russia    Spain  Turkey      UK  \\\n",
       "date                                                                       \n",
       "2020-01-01                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "2020-01-02                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "2020-01-03                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "2020-01-04                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "2020-01-05                  0.0     0.0     0.0      0.0     0.0     0.0   \n",
       "...                         ...     ...     ...      ...     ...     ...   \n",
       "2020-09-14               4408.0  6787.0  5449.0  27404.0  1527.0  3330.0   \n",
       "2020-09-15               3335.0  4241.0  5509.0   9437.0  1716.0  2621.0   \n",
       "2020-09-16               4771.0  4160.0  5529.0  11193.0  1742.0  3103.0   \n",
       "2020-09-17               4444.0  6380.0  5670.0  11291.0  1771.0  3991.0   \n",
       "2020-09-18               3182.0  5698.0  5762.0  14389.0  1648.0  3395.0   \n",
       "\n",
       "countriesAndTerritories      USA  \n",
       "date                              \n",
       "2020-01-01                   0.0  \n",
       "2020-01-02                   0.0  \n",
       "2020-01-03                   0.0  \n",
       "2020-01-04                   0.0  \n",
       "2020-01-05                   0.0  \n",
       "...                          ...  \n",
       "2020-09-14               33871.0  \n",
       "2020-09-15               34841.0  \n",
       "2020-09-16               51473.0  \n",
       "2020-09-17               24598.0  \n",
       "2020-09-18               43567.0  \n",
       "\n",
       "[262 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "covid = pd.read_csv('./exercises/covid19_cases.csv').assign( #step a\n",
    "    date=lambda x: pd.to_datetime(x.dateRep, format='%d/%m/%Y') #step b\n",
    ").set_index('date').replace( # why does this line start with a close parenthesis?\n",
    "    'United_States_of_America', 'USA'\n",
    ").replace('United_Kingdom', 'UK').sort_index()#step d\n",
    "\n",
    "covid[\n",
    "    covid.countriesAndTerritories.isin([\n",
    "        'Argentina', 'Brazil', 'China', 'Colombia', 'India', 'Italy', \n",
    "        'Mexico', 'Peru', 'Russia', 'Spain', 'Turkey', 'UK', 'USA'\n",
    "    ]) #step e\n",
    "].reset_index().pivot(index='date', columns='countriesAndTerritories', values='cases').fillna(0) #step f\n",
    "\n",
    "#This was difficult for me and I used the solution quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e7b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
